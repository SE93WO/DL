{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8GaDltECkKM",
        "colab_type": "code",
        "outputId": "ebffe580-3eab-4b65-b8de-3bc4acc10928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, History\n",
        "from tensorflow.contrib.tpu.python.tpu import keras_support\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "import pickle, os, time\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OYaZVsEGla5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OctConv2D(layers.Layer):\n",
        "    def __init__(self, filters, alpha, kernel_size=(3,3), strides=(1,1), \n",
        "                    padding=\"same\", kernel_initializer='glorot_uniform',\n",
        "                    kernel_regularizer=None, kernel_constraint=None,\n",
        "                    **kwargs):\n",
        "\n",
        "        assert alpha >= 0 and alpha <= 1\n",
        "        assert filters > 0 and isinstance(filters, int)\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.filters = filters\n",
        "   \n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "        self.kernel_constraint = kernel_constraint\n",
        "\n",
        "        self.low_channels = int(self.filters * self.alpha)\n",
        "        self.high_channels = self.filters - self.low_channels\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 2\n",
        "        assert len(input_shape[0]) == 4 and len(input_shape[1]) == 4\n",
        "  \n",
        "        assert input_shape[0][1] // 2 >= self.kernel_size[0]\n",
        "        assert input_shape[0][2] // 2 >= self.kernel_size[1]\n",
        "\n",
        "        assert input_shape[0][1] // input_shape[1][1] == 2\n",
        "        assert input_shape[0][2] // input_shape[1][2] == 2\n",
        "\n",
        "        assert K.image_data_format() == \"channels_last\"\n",
        "\n",
        "        high_in = int(input_shape[0][3])\n",
        "        low_in = int(input_shape[1][3])\n",
        "\n",
        "        self.high_to_high_kernel = self.add_weight(name=\"high_to_high_kernel\", \n",
        "                                    shape=(*self.kernel_size, high_in, self.high_channels),\n",
        "                                    initializer=self.kernel_initializer,\n",
        "                                    regularizer=self.kernel_regularizer,\n",
        "                                    constraint=self.kernel_constraint)\n",
        "\n",
        "        self.high_to_low_kernel  = self.add_weight(name=\"high_to_low_kernel\", \n",
        "                                    shape=(*self.kernel_size, high_in, self.low_channels),\n",
        "                                    initializer=self.kernel_initializer,\n",
        "                                    regularizer=self.kernel_regularizer,\n",
        "                                    constraint=self.kernel_constraint)\n",
        "\n",
        "        self.low_to_high_kernel  = self.add_weight(name=\"low_to_high_kernel\", \n",
        "                                    shape=(*self.kernel_size, low_in, self.high_channels),\n",
        "                                    initializer=self.kernel_initializer,\n",
        "                                    regularizer=self.kernel_regularizer,\n",
        "                                    constraint=self.kernel_constraint)\n",
        "\n",
        "        self.low_to_low_kernel   = self.add_weight(name=\"low_to_low_kernel\", \n",
        "                                    shape=(*self.kernel_size, low_in, self.low_channels),\n",
        "                                    initializer=self.kernel_initializer,\n",
        "                                    regularizer=self.kernel_regularizer,\n",
        "                                    constraint=self.kernel_constraint)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "  \n",
        "        assert len(inputs) == 2\n",
        "        high_input, low_input = inputs\n",
        "\n",
        "        high_to_high = K.conv2d(high_input, self.high_to_high_kernel,\n",
        "                                strides=self.strides, padding=self.padding,\n",
        "                                data_format=\"channels_last\")\n",
        "\n",
        "        high_to_low  = K.pool2d(high_input, (2,2), strides=(2,2), pool_mode=\"avg\")\n",
        "        high_to_low  = K.conv2d(high_to_low, self.high_to_low_kernel,\n",
        "                                strides=self.strides, padding=self.padding,\n",
        "                                data_format=\"channels_last\")\n",
        " \n",
        "        low_to_high  = K.conv2d(low_input, self.low_to_high_kernel,\n",
        "                                strides=self.strides, padding=self.padding,\n",
        "                                data_format=\"channels_last\")\n",
        "        low_to_high = K.repeat_elements(low_to_high, 2, axis=1)\n",
        "        low_to_high = K.repeat_elements(low_to_high, 2, axis=2)\n",
        "    \n",
        "        low_to_low   = K.conv2d(low_input, self.low_to_low_kernel,\n",
        "                                strides=self.strides, padding=self.padding,\n",
        "                                data_format=\"channels_last\")\n",
        "   \n",
        "        high_add = high_to_high + low_to_high\n",
        "        low_add = high_to_low + low_to_low\n",
        "        return [high_add, low_add]\n",
        "\n",
        "    def compute_output_shape(self, input_shapes):\n",
        "        high_in_shape, low_in_shape = input_shapes\n",
        "        high_out_shape = (*high_in_shape[:3], self.high_channels)\n",
        "        low_out_shape = (*low_in_shape[:3], self.low_channels)\n",
        "        return [high_out_shape, low_out_shape]\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        out_config = {\n",
        "            **base_config,\n",
        "            \"filters\": self.filters,\n",
        "            \"alpha\": self.alpha,\n",
        "            \"filters\": self.filters,\n",
        "            \"kernel_size\": self.kernel_size,\n",
        "            \"strides\": self.strides,\n",
        "            \"padding\": self.padding,\n",
        "            \"kernel_initializer\": self.kernel_initializer,\n",
        "            \"kernel_regularizer\": self.kernel_regularizer,\n",
        "            \"kernel_constraint\": self.kernel_constraint,            \n",
        "        }\n",
        "        return out_config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHbXUcQGVv4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_normal_residual_block(inputs, ch, N):\n",
        "    x = inputs\n",
        "    for i in range(N):\n",
        "        if i == 0:\n",
        "            skip = layers.Conv2D(ch, 1)(x)\n",
        "            skip = layers.BatchNormalization()(skip)\n",
        "            skip = layers.Activation(\"relu\")(skip)\n",
        "        else:\n",
        "            skip = x\n",
        "        x = layers.Conv2D(ch, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2D(ch, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Add()([x, skip])\n",
        "    return x\n",
        "\n",
        "def create_octconv_residual_block(inputs, ch, N, alpha):\n",
        "    high, low = inputs\n",
        "    for i in range(N):\n",
        "        if i == 0:\n",
        "            skip_high = layers.Conv2D(int(ch*(1-alpha)), 1)(high)\n",
        "            skip_high = layers.BatchNormalization()(skip_high)\n",
        "            skip_high = layers.Activation(\"relu\")(skip_high)\n",
        "\n",
        "            skip_low = layers.Conv2D(int(ch*alpha), 1)(low)\n",
        "            skip_low = layers.BatchNormalization()(skip_low)\n",
        "            skip_low = layers.Activation(\"relu\")(skip_low)\n",
        "        else:\n",
        "            skip_high, skip_low = high, low\n",
        "\n",
        "        high, low = OctConv2D(filters=ch, alpha=alpha)([high, low])\n",
        "        high = layers.BatchNormalization()(high)\n",
        "        high = layers.Activation(\"relu\")(high)\n",
        "        low = layers.BatchNormalization()(low)\n",
        "        low = layers.Activation(\"relu\")(low)\n",
        "\n",
        "        high, low = OctConv2D(filters=ch, alpha=alpha)([high, low])\n",
        "        high = layers.BatchNormalization()(high)\n",
        "        high = layers.Activation(\"relu\")(high)\n",
        "        low = layers.BatchNormalization()(low)\n",
        "        low = layers.Activation(\"relu\")(low)\n",
        "\n",
        "        high = layers.Add()([high, skip_high])\n",
        "        low = layers.Add()([low, skip_low])\n",
        "    return [high, low]\n",
        "\n",
        "def create_octconv_last_residual_block(inputs, ch, alpha):\n",
        "    high, low = inputs\n",
        "\n",
        "    high, low = OctConv2D(filters=ch, alpha=alpha)([high, low])\n",
        "    high = layers.BatchNormalization()(high)\n",
        "    high = layers.Activation(\"relu\")(high)\n",
        "    low = layers.BatchNormalization()(low)\n",
        "    low = layers.Activation(\"relu\")(low)\n",
        "\n",
        "    high_to_high = layers.Conv2D(ch, 3, padding=\"same\")(high)\n",
        "    low_to_high = layers.Conv2D(ch, 3, padding=\"same\")(low)\n",
        "    low_to_high = layers.Lambda(lambda x: \n",
        "                        K.repeat_elements(K.repeat_elements(x, 2, axis=1), 2, axis=2))(low_to_high)\n",
        "    x = layers.Add()([high_to_high, low_to_high])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0xa54_-WbVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_normal_wide_resnet(N=4, k=10):\n",
        "    input = layers.Input((32,32,3))\n",
        "    x = layers.Conv2D(16, 3, padding=\"same\")(input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = create_normal_residual_block(x, 16*k, N)\n",
        "    x = layers.AveragePooling2D(2)(x)\n",
        "    x = create_normal_residual_block(x, 32*k, N)\n",
        "    x = layers.AveragePooling2D(2)(x)\n",
        "    x = create_normal_residual_block(x, 64*k, N)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(input, x)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioIxKTsmWern",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_octconv_wide_resnet(alpha, N=4, k=10):\n",
        "\n",
        "    input = layers.Input((32,32,3))\n",
        "    low = layers.AveragePooling2D(2)(input)\n",
        "\n",
        "    high, low = OctConv2D(filters=16, alpha=alpha)([input, low])\n",
        "    high = layers.BatchNormalization()(high)\n",
        "    high = layers.Activation(\"relu\")(high)\n",
        "    low = layers.BatchNormalization()(low)\n",
        "    low = layers.Activation(\"relu\")(low)\n",
        "\n",
        "    high, low = create_octconv_residual_block([high, low], 16*k, N, alpha)\n",
        " \n",
        "    high = layers.AveragePooling2D(2)(high)\n",
        "    low = layers.AveragePooling2D(2)(low)\n",
        "    high, low = create_octconv_residual_block([high, low], 32*k, N, alpha)\n",
        "\n",
        "    high = layers.AveragePooling2D(2)(high)\n",
        "    low = layers.AveragePooling2D(2)(low)\n",
        "    high, low = create_octconv_residual_block([high, low], 64*k, N-1, alpha)\n",
        "\n",
        "    x = create_octconv_last_residual_block([high, low], 64*k, alpha)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(input, x)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VIuP8P5W7n3",
        "colab_type": "code",
        "outputId": "0b344935-75a0-4c0f-9d63-3a56c136fd2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def lr_scheduler(epoch):\n",
        "    x = 0.1\n",
        "    if epoch >= 100: x /= 5.0\n",
        "    if epoch >= 150: x /= 5.0\n",
        "    return x\n",
        "\n",
        "def train(alpha):\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    train_gen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, \n",
        "                                    width_shift_range=4.0/32.0, height_shift_range=4.0/32.0)\n",
        "    test_gen = ImageDataGenerator(rescale=1.0/255)\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)\n",
        "\n",
        "    tf.logging.set_verbosity(tf.logging.FATAL)\n",
        "\n",
        "    if alpha <= 0:\n",
        "        model = create_normal_wide_resnet()\n",
        "    else:\n",
        "        model = create_octconv_wide_resnet(alpha)\n",
        "    model.compile(SGD(0.1, momentum=0.9), \"categorical_crossentropy\", [\"acc\"])\n",
        "    model.summary()\n",
        "\n",
        "    batch_size = 128\n",
        "    scheduler = LearningRateScheduler(lr_scheduler)\n",
        "    hist = History()\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit_generator(train_gen.flow(X_train, y_train, batch_size, shuffle=True),\n",
        "                        steps_per_epoch=X_train.shape[0]//batch_size,\n",
        "                        validation_data=test_gen.flow(X_test, y_test, batch_size, shuffle=False),\n",
        "                        validation_steps=X_test.shape[0]//batch_size,\n",
        "                        callbacks=[scheduler, hist], max_queue_size=5, epochs=20)\n",
        "    elapsed = time.time() - start_time\n",
        "    print(elapsed)\n",
        "\n",
        "    history = hist.history\n",
        "    history[\"elapsed\"] = elapsed\n",
        "\n",
        "train(0.25)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 16, 16, 3)    0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_48 (OctConv2D)       [(None, 32, 32, 12), 864         input_4[0][0]                    \n",
            "                                                                 average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 32, 32, 12)   48          oct_conv2d_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 16, 16, 4)    16          oct_conv2d_48[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 32, 32, 12)   0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 16, 16, 4)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_49 (OctConv2D)       [(None, 32, 32, 120) 23040       activation_138[0][0]             \n",
            "                                                                 activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 32, 32, 120)  480         oct_conv2d_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 16, 16, 40)   160         oct_conv2d_49[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 32, 32, 120)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 16, 16, 40)   0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_50 (OctConv2D)       [(None, 32, 32, 120) 230400      activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 32, 32, 120)  1560        activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 40)   200         activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 32, 32, 120)  480         oct_conv2d_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 32, 32, 120)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 16, 16, 40)   160         oct_conv2d_50[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 16, 16, 40)   160         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 32, 32, 120)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 32, 32, 120)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 16, 16, 40)   0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 16, 16, 40)   0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 32, 32, 120)  0           activation_144[0][0]             \n",
            "                                                                 activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 16, 16, 40)   0           activation_145[0][0]             \n",
            "                                                                 activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_51 (OctConv2D)       [(None, 32, 32, 120) 230400      add_58[0][0]                     \n",
            "                                                                 add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 32, 32, 120)  480         oct_conv2d_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 16, 16, 40)   160         oct_conv2d_51[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 32, 32, 120)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 16, 16, 40)   0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_52 (OctConv2D)       [(None, 32, 32, 120) 230400      activation_146[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 32, 32, 120)  480         oct_conv2d_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 16, 16, 40)   160         oct_conv2d_52[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 32, 32, 120)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 16, 16, 40)   0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 32, 32, 120)  0           activation_148[0][0]             \n",
            "                                                                 add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 16, 16, 40)   0           activation_149[0][0]             \n",
            "                                                                 add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_53 (OctConv2D)       [(None, 32, 32, 120) 230400      add_60[0][0]                     \n",
            "                                                                 add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 32, 32, 120)  480         oct_conv2d_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 16, 16, 40)   160         oct_conv2d_53[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 32, 32, 120)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 16, 16, 40)   0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_54 (OctConv2D)       [(None, 32, 32, 120) 230400      activation_150[0][0]             \n",
            "                                                                 activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 32, 32, 120)  480         oct_conv2d_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 16, 16, 40)   160         oct_conv2d_54[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 32, 32, 120)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 16, 16, 40)   0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 32, 32, 120)  0           activation_152[0][0]             \n",
            "                                                                 add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 16, 16, 40)   0           activation_153[0][0]             \n",
            "                                                                 add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_55 (OctConv2D)       [(None, 32, 32, 120) 230400      add_62[0][0]                     \n",
            "                                                                 add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 32, 32, 120)  480         oct_conv2d_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 16, 16, 40)   160         oct_conv2d_55[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 32, 32, 120)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 16, 16, 40)   0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_56 (OctConv2D)       [(None, 32, 32, 120) 230400      activation_154[0][0]             \n",
            "                                                                 activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 32, 32, 120)  480         oct_conv2d_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 16, 16, 40)   160         oct_conv2d_56[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 32, 32, 120)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 16, 16, 40)   0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 32, 32, 120)  0           activation_156[0][0]             \n",
            "                                                                 add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 16, 16, 40)   0           activation_157[0][0]             \n",
            "                                                                 add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 16, 16, 120)  0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 8, 8, 40)     0           add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_57 (OctConv2D)       [(None, 16, 16, 240) 460800      average_pooling2d_13[0][0]       \n",
            "                                                                 average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 16, 16, 240)  960         oct_conv2d_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 8, 8, 80)     320         oct_conv2d_57[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 16, 16, 240)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 8, 8, 80)     0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_58 (OctConv2D)       [(None, 16, 16, 240) 921600      activation_160[0][0]             \n",
            "                                                                 activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 240)  29040       average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 8, 8, 80)     3280        average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 16, 16, 240)  960         oct_conv2d_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 16, 16, 240)  960         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 8, 8, 80)     320         oct_conv2d_58[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 8, 8, 80)     320         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 16, 16, 240)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 16, 16, 240)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 8, 8, 80)     0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 8, 8, 80)     0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 16, 16, 240)  0           activation_162[0][0]             \n",
            "                                                                 activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 8, 8, 80)     0           activation_163[0][0]             \n",
            "                                                                 activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_59 (OctConv2D)       [(None, 16, 16, 240) 921600      add_66[0][0]                     \n",
            "                                                                 add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 16, 16, 240)  960         oct_conv2d_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 8, 8, 80)     320         oct_conv2d_59[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 16, 16, 240)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 8, 8, 80)     0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_60 (OctConv2D)       [(None, 16, 16, 240) 921600      activation_164[0][0]             \n",
            "                                                                 activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 16, 16, 240)  960         oct_conv2d_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 8, 8, 80)     320         oct_conv2d_60[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 16, 16, 240)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 8, 8, 80)     0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_68 (Add)                    (None, 16, 16, 240)  0           activation_166[0][0]             \n",
            "                                                                 add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_69 (Add)                    (None, 8, 8, 80)     0           activation_167[0][0]             \n",
            "                                                                 add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_61 (OctConv2D)       [(None, 16, 16, 240) 921600      add_68[0][0]                     \n",
            "                                                                 add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 16, 16, 240)  960         oct_conv2d_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 8, 8, 80)     320         oct_conv2d_61[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 16, 16, 240)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 8, 8, 80)     0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_62 (OctConv2D)       [(None, 16, 16, 240) 921600      activation_168[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 16, 16, 240)  960         oct_conv2d_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 80)     320         oct_conv2d_62[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 16, 16, 240)  0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 8, 8, 80)     0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, 16, 16, 240)  0           activation_170[0][0]             \n",
            "                                                                 add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_71 (Add)                    (None, 8, 8, 80)     0           activation_171[0][0]             \n",
            "                                                                 add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_63 (OctConv2D)       [(None, 16, 16, 240) 921600      add_70[0][0]                     \n",
            "                                                                 add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 16, 16, 240)  960         oct_conv2d_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 8, 8, 80)     320         oct_conv2d_63[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 16, 16, 240)  0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 8, 8, 80)     0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_64 (OctConv2D)       [(None, 16, 16, 240) 921600      activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 16, 16, 240)  960         oct_conv2d_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 8, 8, 80)     320         oct_conv2d_64[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 16, 16, 240)  0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 8, 8, 80)     0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_72 (Add)                    (None, 16, 16, 240)  0           activation_174[0][0]             \n",
            "                                                                 add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_73 (Add)                    (None, 8, 8, 80)     0           activation_175[0][0]             \n",
            "                                                                 add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 8, 8, 240)    0           add_72[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 4, 4, 80)     0           add_73[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_65 (OctConv2D)       [(None, 8, 8, 480),  1843200     average_pooling2d_15[0][0]       \n",
            "                                                                 average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 480)    1920        oct_conv2d_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 4, 4, 160)    640         oct_conv2d_65[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 8, 8, 480)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 4, 4, 160)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_66 (OctConv2D)       [(None, 8, 8, 480),  3686400     activation_178[0][0]             \n",
            "                                                                 activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 8, 8, 480)    115680      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 160)    12960       average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 480)    1920        oct_conv2d_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 480)    1920        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 4, 4, 160)    640         oct_conv2d_66[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 4, 4, 160)    640         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 8, 8, 480)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 8, 8, 480)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 4, 4, 160)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 4, 4, 160)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_74 (Add)                    (None, 8, 8, 480)    0           activation_180[0][0]             \n",
            "                                                                 activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 4, 4, 160)    0           activation_181[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_67 (OctConv2D)       [(None, 8, 8, 480),  3686400     add_74[0][0]                     \n",
            "                                                                 add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 480)    1920        oct_conv2d_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 4, 4, 160)    640         oct_conv2d_67[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 480)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 4, 4, 160)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_68 (OctConv2D)       [(None, 8, 8, 480),  3686400     activation_182[0][0]             \n",
            "                                                                 activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 480)    1920        oct_conv2d_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 4, 4, 160)    640         oct_conv2d_68[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 480)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 4, 4, 160)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_76 (Add)                    (None, 8, 8, 480)    0           activation_184[0][0]             \n",
            "                                                                 add_74[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_77 (Add)                    (None, 4, 4, 160)    0           activation_185[0][0]             \n",
            "                                                                 add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_69 (OctConv2D)       [(None, 8, 8, 480),  3686400     add_76[0][0]                     \n",
            "                                                                 add_77[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 8, 8, 480)    1920        oct_conv2d_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 4, 4, 160)    640         oct_conv2d_69[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 480)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 4, 4, 160)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_70 (OctConv2D)       [(None, 8, 8, 480),  3686400     activation_186[0][0]             \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 8, 8, 480)    1920        oct_conv2d_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 4, 4, 160)    640         oct_conv2d_70[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 8, 8, 480)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 4, 4, 160)    0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_78 (Add)                    (None, 8, 8, 480)    0           activation_188[0][0]             \n",
            "                                                                 add_76[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_79 (Add)                    (None, 4, 4, 160)    0           activation_189[0][0]             \n",
            "                                                                 add_77[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "oct_conv2d_71 (OctConv2D)       [(None, 8, 8, 480),  3686400     add_78[0][0]                     \n",
            "                                                                 add_79[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 4, 4, 160)    640         oct_conv2d_71[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 8, 8, 480)    1920        oct_conv2d_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 4, 4, 160)    0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 8, 8, 480)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 640)    922240      activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 8, 8, 640)    2765440     activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 8, 8, 640)    0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_80 (Add)                    (None, 8, 8, 640)    0           conv2d_50[0][0]                  \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 8, 8, 640)    2560        add_80[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 8, 8, 640)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 640)          0           activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           6410        global_average_pooling2d_3[0][0] \n",
            "==================================================================================================\n",
            "Total params: 36,407,498\n",
            "Trainable params: 36,387,306\n",
            "Non-trainable params: 20,192\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.7650 - acc: 0.3607Epoch 1/20\n",
            "390/390 [==============================] - 289s 740ms/step - loss: 1.7640 - acc: 0.3610 - val_loss: 2.0455 - val_acc: 0.3540\n",
            "Epoch 2/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 1.2344 - acc: 0.5560Epoch 1/20\n",
            "390/390 [==============================] - 266s 683ms/step - loss: 1.2340 - acc: 0.5562 - val_loss: 1.2408 - val_acc: 0.5712\n",
            "Epoch 3/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.8857 - acc: 0.6886Epoch 1/20\n",
            "390/390 [==============================] - 267s 684ms/step - loss: 0.8853 - acc: 0.6887 - val_loss: 1.2497 - val_acc: 0.6072\n",
            "Epoch 4/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.6922 - acc: 0.7575Epoch 1/20\n",
            "390/390 [==============================] - 266s 683ms/step - loss: 0.6921 - acc: 0.7575 - val_loss: 0.7594 - val_acc: 0.7292\n",
            "Epoch 5/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.5624 - acc: 0.8053Epoch 1/20\n",
            "390/390 [==============================] - 266s 683ms/step - loss: 0.5623 - acc: 0.8054 - val_loss: 0.7768 - val_acc: 0.7427\n",
            "Epoch 6/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.8330Epoch 1/20\n",
            "390/390 [==============================] - 267s 684ms/step - loss: 0.4836 - acc: 0.8331 - val_loss: 1.1938 - val_acc: 0.6557\n",
            "Epoch 7/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.4191 - acc: 0.8550Epoch 1/20\n",
            "390/390 [==============================] - 266s 683ms/step - loss: 0.4189 - acc: 0.8551 - val_loss: 0.7686 - val_acc: 0.7595\n",
            "Epoch 8/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3692 - acc: 0.8741Epoch 1/20\n",
            "390/390 [==============================] - 267s 685ms/step - loss: 0.3690 - acc: 0.8742 - val_loss: 0.7887 - val_acc: 0.7417\n",
            "Epoch 9/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.3248 - acc: 0.8869Epoch 1/20\n",
            "390/390 [==============================] - 267s 686ms/step - loss: 0.3247 - acc: 0.8870 - val_loss: 0.4822 - val_acc: 0.8447\n",
            "Epoch 10/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.8977Epoch 1/20\n",
            "390/390 [==============================] - 267s 685ms/step - loss: 0.2927 - acc: 0.8978 - val_loss: 0.6365 - val_acc: 0.8038\n",
            "Epoch 11/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2661 - acc: 0.9079Epoch 1/20\n",
            "390/390 [==============================] - 267s 684ms/step - loss: 0.2659 - acc: 0.9079 - val_loss: 0.5425 - val_acc: 0.8379\n",
            "Epoch 12/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2375 - acc: 0.9165Epoch 1/20\n",
            "390/390 [==============================] - 267s 686ms/step - loss: 0.2374 - acc: 0.9166 - val_loss: 1.0130 - val_acc: 0.7361\n",
            "Epoch 13/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9232Epoch 1/20\n",
            "390/390 [==============================] - 267s 686ms/step - loss: 0.2189 - acc: 0.9233 - val_loss: 0.8003 - val_acc: 0.7830\n",
            "Epoch 14/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9309Epoch 1/20\n",
            "390/390 [==============================] - 267s 684ms/step - loss: 0.1975 - acc: 0.9309 - val_loss: 0.6584 - val_acc: 0.8242\n",
            "Epoch 15/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.1783 - acc: 0.9359Epoch 1/20\n",
            "390/390 [==============================] - 267s 684ms/step - loss: 0.1785 - acc: 0.9358 - val_loss: 0.6490 - val_acc: 0.8206\n",
            "Epoch 16/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9438Epoch 1/20\n",
            "390/390 [==============================] - 267s 684ms/step - loss: 0.1633 - acc: 0.9437 - val_loss: 0.5129 - val_acc: 0.8464\n",
            "Epoch 17/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9474Epoch 1/20\n",
            "390/390 [==============================] - 267s 684ms/step - loss: 0.1492 - acc: 0.9474 - val_loss: 0.5515 - val_acc: 0.8443\n",
            "Epoch 18/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9515Epoch 1/20\n",
            "390/390 [==============================] - 266s 683ms/step - loss: 0.1371 - acc: 0.9514 - val_loss: 0.6426 - val_acc: 0.8388\n",
            "Epoch 19/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9547Epoch 1/20\n",
            "390/390 [==============================] - 266s 683ms/step - loss: 0.1280 - acc: 0.9546 - val_loss: 0.4897 - val_acc: 0.8624\n",
            "Epoch 20/20\n",
            "389/390 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9598Epoch 1/20\n",
            "390/390 [==============================] - 266s 682ms/step - loss: 0.1169 - acc: 0.9597 - val_loss: 0.4913 - val_acc: 0.8574\n",
            "5364.555780887604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9EsZ7ayXyHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}