{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SEWO.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vtp9xikALsD0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.layers import Input, Dense, Conv2D, SeparableConv2D\n",
        "from keras.layers import MaxPool2D, AvgPool2D, GlobalAvgPool2D\n",
        "from keras.layers import BatchNormalization, add, ReLU, Activation\n",
        "from keras.utils import np_utils\n",
        "cifar100 = tf.keras.datasets.cifar100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "y_train = np_utils.to_categorical(y_train, 100)\n",
        "y_test = np_utils.to_categorical(y_test, 100)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train  /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dhe3Mtyhemhg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "|def xception_1(input_shape, n_classes):\n",
        "  input = tf.keras.layers.Input(input_shape)\n",
        "  \n",
        "  x = tf.layers.Conv2D(32, kernel_size=(3, 3), use_bias=False)(input)\n",
        "  x = tf.layers.batch_normalization(x)\n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.layers.Conv2D(64, kernel_size=(3, 3), use_bias=False)(x)\n",
        "  x = tf.layers.batch_normalization(x)\n",
        "  x = tf.nn.relu(x)\n",
        "  residual = tf.layers.Conv2D(128, kernel_size=(1, 1), padding='same')(x)\n",
        "  residual = tf.layers.batch_normalization(residual)\n",
        "  \n",
        "  x = tf.layers.separable_conv2d(inputs=x, filters=128, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.layers.batch_normalization(x)\n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.layers.separable_conv2d(inputs=x, filters=128, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.layers.batch_normalization(x)\n",
        "  x = tf.layers.MaxPooling2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
        "  x = tf.add(x, residual)\n",
        "  residual = tf.layers.Conv2D(256, kernel_size=(1, 1), padding='same', use_bias=False)(x)\n",
        "  residual = tf.layers.batch_normalization(residual)\n",
        "  \n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.layers.separable_conv2d(inputs=x, filters=256, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.layers.batch_normalization(x)\n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.layers.separable_conv2d(inputs=x, filters=256, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.layers.MaxPooling2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
        "  x = tf.add(x, residual)\n",
        "  residual = tf.layers.Conv2D(728, kernel_size=(1, 1), padding='same', use_bias=False)(x)\n",
        "  residual = tf.layers.batch_normalization(residual)\n",
        "  \n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.layers.separable_conv2d(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.layers.batch_normalization(x)\n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.layers.separable_conv2d(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.layers.MaxPooling2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
        "  x = tf.add(x, residual)\n",
        "  \n",
        "  for i in range(8):\n",
        "    residual = x\n",
        "    \n",
        "    x = tf.nn.relu(x)\n",
        "    x = tf.layers.separable_conv2d(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "    x = tf.layers.batch_normalization(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = tf.layers.separable_conv2d(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "    x = tf.layers.batch_normalization(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = tf.layers.separable_conv2d(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "    x = tf.layers.batch_normalization(x)\n",
        "    x = tf.add(x, residual)\n",
        "    \n",
        "  residual = tf.layers.Conv2D(1024, kernel_size=(1, 1), padding='same', use_bias=False)(x)\n",
        "  residual = tf.layers.batch_normalization(residual)\n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.layers.separable_conv2d(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.layers.batch_normalization(x)\n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.layers.separable_conv2d(inputs=x, filters=1024, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.layers.batch_normalization(x)\n",
        "  x = tf.layers.MaxPooling2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
        "  x = tf.add(x, residual)\n",
        "  \n",
        "  x = tf.layers.separable_conv2d(inputs=x, filters=1536, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.layers.batch_normalization(x)\n",
        "  x = tf.nn.relu(x)\n",
        "  x = tf.layers.separable_conv2d(inputs=x, filters=2048, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.layers.batch_normalization(x)\n",
        "  x = tf.nn.relu(x)\n",
        "  \n",
        "  x = tf.layers.average_pooling2d(inputs=x, pool_size=(10,10), strides=1, padding='same')\n",
        "\n",
        "  output = tf.layers.Dense(n_classes, activation='softmax')(x)\n",
        "  model = tf.keras.Model(input, output)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ESIuXdZXeCks",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xception_2(input_shape, n_classes):\n",
        "  input = tf.keras.layers.Input(input_shape)\n",
        "  \n",
        "  x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), use_bias=False)(input)\n",
        "  x = tf.keras.layers.BatchNormalization(x)\n",
        "  x = tf.keras.activations.relu(x)\n",
        "  x = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), use_bias=False)(x)\n",
        "  x = tf.keras.layers.BatchNormalization(x)\n",
        "  x = tf.keras.activations.relu(x)\n",
        "  residual = tf.keras.layers.Conv2D(128, kernel_size=(1, 1), padding='same')(x)\n",
        "  residual = tf.keras.layers.BatchNormalization(residual)\n",
        "  \n",
        "  x = tf.keras.layers.SeparableConv2D(inputs=x, filters=128, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.keras.layers.BatchNormalization(x)\n",
        "  x = tf.keras.activations.relu(x)\n",
        "  x = tf.keras.layers.SeparableConv2D(inputs=x, filters=128, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.keras.layers.BatchNormalization(x)\n",
        "  x = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
        "  x = keras.layers.Add()([x, residual])\n",
        "  residual = tf.keras.layers.Conv2D(256, kernel_size=(1, 1), padding='same', use_bias=False)(x)\n",
        "  residual = tf.keras.layers.BatchNormalization(residual)\n",
        "  \n",
        "  x = tf.keras.activations.relu(x)\n",
        "  x = tf.keras.layers.SeparableConv2D(inputs=x, filters=256, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.keras.layers.BatchNormalization(x)\n",
        "  x = tf.keras.activations.relu(x)\n",
        "  x = tf.keras.layers.SeparableConv2D(inputs=x, filters=256, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
        "  x = keras.layers.Add()([x, residual])\n",
        "  residual = tf.keras.layers.Conv2D(728, kernel_size=(1, 1), padding='same', use_bias=False)(x)\n",
        "  residual = tf.keras.layers.BatchNormalization(residual)\n",
        "  \n",
        "  x = tf.keras.activations.relu(x)\n",
        "  x = tf.keras.layers.SeparableConv2D(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.keras.layers.BatchNormalization(x)\n",
        "  x = tf.keras.activations.relu(x)\n",
        "  x = tf.keras.layers.SeparableConv2D(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
        "  x = keras.layers.Add()([x, residual])\n",
        "  \n",
        "  for i in range(8):\n",
        "    residual = x\n",
        "    \n",
        "    x = tf.keras.activations.relu(x)\n",
        "    x = tf.keras.layers.SeparableConv2D(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "    x = tf.keras.layers.BatchNormalization(x)\n",
        "    x = tf.keras.activations.relu(x)\n",
        "    x = tf.keras.layers.SeparableConv2D(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "    x = tf.keras.layers.BatchNormalization(x)\n",
        "    x = tf.keras.activations.relu(x)\n",
        "    x = tf.keras.layers.SeparableConv2D(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "    x = tf.keras.layers.BatchNormalization(x)\n",
        "    x = keras.layers.Add()([x, residual])\n",
        "    \n",
        "  residual = tf.keras.layers.Conv2D(1024, kernel_size=(1, 1), padding='same', use_bias=False)(x)\n",
        "  residual = tf.keras.layers.BatchNormalization(residual)\n",
        "  x = tf.keras.activations.relu(x)\n",
        "  x = tf.keras.layers.SeparableConv2D(inputs=x, filters=728, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.keras.layers.BatchNormalization(x)\n",
        "  x = tf.keras.activations.relu(x)\n",
        "  x = tf.keras.layers.SeparableConv2D(inputs=x, filters=1024, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.keras.layers.BatchNormalization(x)\n",
        "  x = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
        "  x = keras.layers.Add()([x, residual])\n",
        "  \n",
        "  x = tf.keras.layers.SeparableConv2D(inputs=x, filters=1536, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.keras.layers.BatchNormalization(x)\n",
        "  x = tf.keras.activations.relu(x)\n",
        "  x = tf.keras.layers.SeparableConv2D(inputs=x, filters=2048, kernel_size=(3, 3), padding='same', use_bias=False)\n",
        "  x = tf.keras.layers.BatchNormalization(x)\n",
        "  x = tf.keras.activations.relu(x)\n",
        "  \n",
        "  x = tf.keras.layers.AveragePooling2D(inputs=x, pool_size=(10,10), strides=1, padding='same')\n",
        "  output = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\n",
        "  model = tf.keras.Model(input, output)\n",
        "  \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCPkoaxBmGPg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xception_3(input_shape, n_classes):\n",
        "  \n",
        "  def conv_bn(x, f, k=1, s=1, p='same'):\n",
        "    x = Conv2D(f, k, strides=s, padding=p)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  def rl_sep(x, f, k=3, s=1, p='same'):\n",
        "    x = ReLU()(x)\n",
        "    x = SeparableConv2D(f, k, strides=s, padding=p)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  def sep_rl(x, f, k=3, s=1, p='same'):\n",
        "    x = SeparableConv2D(f, k, strides=s, padding=p)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  def entry_flow(x, filters):\n",
        "    res = x\n",
        "    for f in filters:\n",
        "      res = conv_bn(res, f, s=2)\n",
        "      x = rl_sep(x, f)\n",
        "      x = rl_sep(x, f)\n",
        "      x = MaxPool2D(3, strides=2, padding='same')(x)\n",
        "      x = add([res, x])\n",
        "    return x\n",
        "      \n",
        "      \n",
        "  def midde_flow(tensor, f):\n",
        "    x = rl_sep(tensor, f)\n",
        "    x = rl_sep(x, f)\n",
        "    x = rl_sep(x, f)\n",
        "    x = add([tensor, x])\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  def exit_flow(x, f):\n",
        "    res = conv_bn(x, f[1], s=2)\n",
        "    \n",
        "    x = rl_sep(x, f[0])\n",
        "    x = rl_sep(x, f[1])\n",
        "    x = MaxPool2D(3, strides=2, padding='same')(x)\n",
        "    x = add([res, x])\n",
        "    \n",
        "    x = sep_rl(x, f[2])\n",
        "    x = sep_rl(x, f[3])\n",
        "    return x\n",
        "  \n",
        "  \n",
        "  input = Input(input_shape)\n",
        "  \n",
        "  x = conv_bn(input, 32, 3, 2)\n",
        "  x = ReLU()(x)\n",
        "  x = conv_bn(input, 64, 3)\n",
        "  x = ReLU()(x)\n",
        "  \n",
        "  x = entry_flow(x, [128, 256, 728])\n",
        "  for _ in range(8):\n",
        "    x = midde_flow(x, 728)\n",
        "  x = exit_flow(x, [728, 1024, 1536, 2048])\n",
        "  \n",
        "  x = GlobalAvgPool2D()(x)\n",
        "  output = Dense(n_classes, activation='softmax')(x)\n",
        "  model = Model(input, output)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_NCZ_7QDRBfY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "n_classes = 100\n",
        "\n",
        "model = xception_3(input_shape, n_classes)\n",
        "sgd = optimizers.SGD(lr=0.045, decay=0.94, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TyDb3-FiRBuJ",
        "colab_type": "code",
        "outputId": "266818d0-d5a8-4448-eab4-77d9d3fb8187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2295
        }
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(horizontal_flip=True, width_shift_range=0.1, height_shift_range=0.1)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=64),\n",
        "                    steps_per_epoch=x_train.shape[0] // 64,\n",
        "                    epochs=60,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "781/781 [==============================] - 235s 301ms/step - loss: 3.4817 - acc: 0.1618 - val_loss: 6.6231 - val_acc: 0.0913\n",
            "Epoch 2/60\n",
            "781/781 [==============================] - 218s 279ms/step - loss: 2.6236 - acc: 0.3134 - val_loss: 3.8522 - val_acc: 0.2059\n",
            "Epoch 3/60\n",
            "781/781 [==============================] - 218s 279ms/step - loss: 2.2189 - acc: 0.4029 - val_loss: 2.9092 - val_acc: 0.3241\n",
            "Epoch 4/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 1.9679 - acc: 0.4612 - val_loss: 3.7179 - val_acc: 0.2764\n",
            "Epoch 5/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 1.7821 - acc: 0.5048 - val_loss: 2.6707 - val_acc: 0.3686\n",
            "Epoch 6/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 1.6446 - acc: 0.5345 - val_loss: 4.5913 - val_acc: 0.2365\n",
            "Epoch 7/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 1.5186 - acc: 0.5665 - val_loss: 2.4165 - val_acc: 0.4262\n",
            "Epoch 8/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 1.4159 - acc: 0.5937 - val_loss: 2.7557 - val_acc: 0.3927\n",
            "Epoch 9/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 1.3196 - acc: 0.6159 - val_loss: 2.2195 - val_acc: 0.4623\n",
            "Epoch 10/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 1.2380 - acc: 0.6381 - val_loss: 2.2959 - val_acc: 0.4651\n",
            "Epoch 11/60\n",
            "781/781 [==============================] - 218s 279ms/step - loss: 1.1573 - acc: 0.6551 - val_loss: 2.4973 - val_acc: 0.4550\n",
            "Epoch 12/60\n",
            "781/781 [==============================] - 218s 279ms/step - loss: 1.0924 - acc: 0.6727 - val_loss: 3.4026 - val_acc: 0.3477\n",
            "Epoch 13/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 1.0269 - acc: 0.6896 - val_loss: 2.2395 - val_acc: 0.4900\n",
            "Epoch 14/60\n",
            "781/781 [==============================] - 218s 279ms/step - loss: 0.9635 - acc: 0.7110 - val_loss: 1.9807 - val_acc: 0.5401\n",
            "Epoch 15/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.9039 - acc: 0.7245 - val_loss: 2.2162 - val_acc: 0.5072\n",
            "Epoch 16/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.8547 - acc: 0.7344 - val_loss: 2.3012 - val_acc: 0.5068\n",
            "Epoch 17/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.8018 - acc: 0.7540 - val_loss: 2.4168 - val_acc: 0.4973\n",
            "Epoch 18/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.7673 - acc: 0.7611 - val_loss: 2.3754 - val_acc: 0.4912\n",
            "Epoch 19/60\n",
            "781/781 [==============================] - 216s 277ms/step - loss: 0.7159 - acc: 0.7772 - val_loss: 2.6430 - val_acc: 0.4761\n",
            "Epoch 20/60\n",
            "781/781 [==============================] - 216s 277ms/step - loss: 0.6811 - acc: 0.7865 - val_loss: 1.9009 - val_acc: 0.5738\n",
            "Epoch 21/60\n",
            "781/781 [==============================] - 217s 277ms/step - loss: 0.6449 - acc: 0.7951 - val_loss: 2.6334 - val_acc: 0.4891\n",
            "Epoch 22/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.6045 - acc: 0.8082 - val_loss: 2.2378 - val_acc: 0.5336\n",
            "Epoch 23/60\n",
            "781/781 [==============================] - 216s 277ms/step - loss: 0.5859 - acc: 0.8125 - val_loss: 2.3502 - val_acc: 0.5208\n",
            "Epoch 24/60\n",
            "781/781 [==============================] - 217s 277ms/step - loss: 0.5470 - acc: 0.8239 - val_loss: 2.1527 - val_acc: 0.5471\n",
            "Epoch 25/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.5150 - acc: 0.8347 - val_loss: 2.2789 - val_acc: 0.5532\n",
            "Epoch 26/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.4904 - acc: 0.8416 - val_loss: 1.9960 - val_acc: 0.5770\n",
            "Epoch 27/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.4649 - acc: 0.8497 - val_loss: 2.3687 - val_acc: 0.5347\n",
            "Epoch 28/60\n",
            "781/781 [==============================] - 218s 279ms/step - loss: 0.4468 - acc: 0.8552 - val_loss: 2.5512 - val_acc: 0.5313\n",
            "Epoch 29/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.4206 - acc: 0.8616 - val_loss: 1.9551 - val_acc: 0.5874\n",
            "Epoch 30/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.4032 - acc: 0.8671 - val_loss: 2.5331 - val_acc: 0.5436\n",
            "Epoch 31/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.3862 - acc: 0.8739 - val_loss: 2.0175 - val_acc: 0.5913\n",
            "Epoch 32/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.3715 - acc: 0.8778 - val_loss: 2.2393 - val_acc: 0.5654\n",
            "Epoch 33/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.3603 - acc: 0.8800 - val_loss: 2.1211 - val_acc: 0.5909\n",
            "Epoch 34/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.3507 - acc: 0.8851 - val_loss: 2.0885 - val_acc: 0.5951\n",
            "Epoch 35/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.3257 - acc: 0.8918 - val_loss: 2.0624 - val_acc: 0.6024\n",
            "Epoch 36/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.3115 - acc: 0.8982 - val_loss: 2.2823 - val_acc: 0.5608\n",
            "Epoch 37/60\n",
            "781/781 [==============================] - 218s 279ms/step - loss: 0.3139 - acc: 0.8975 - val_loss: 2.3910 - val_acc: 0.5644\n",
            "Epoch 38/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.2957 - acc: 0.9015 - val_loss: 2.1559 - val_acc: 0.6031\n",
            "Epoch 39/60\n",
            "781/781 [==============================] - 217s 277ms/step - loss: 0.2884 - acc: 0.9047 - val_loss: 2.2458 - val_acc: 0.5901\n",
            "Epoch 40/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.2751 - acc: 0.9077 - val_loss: 2.5660 - val_acc: 0.5609\n",
            "Epoch 41/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.2636 - acc: 0.9131 - val_loss: 2.6968 - val_acc: 0.5499\n",
            "Epoch 42/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.2498 - acc: 0.9175 - val_loss: 2.4983 - val_acc: 0.5735\n",
            "Epoch 43/60\n",
            "781/781 [==============================] - 217s 277ms/step - loss: 0.2486 - acc: 0.9161 - val_loss: 2.3540 - val_acc: 0.5785\n",
            "Epoch 44/60\n",
            "781/781 [==============================] - 217s 277ms/step - loss: 0.2401 - acc: 0.9214 - val_loss: 2.2024 - val_acc: 0.6029\n",
            "Epoch 45/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.2338 - acc: 0.9222 - val_loss: 2.6529 - val_acc: 0.5635\n",
            "Epoch 46/60\n",
            "781/781 [==============================] - 217s 277ms/step - loss: 0.2296 - acc: 0.9241 - val_loss: 2.1784 - val_acc: 0.6056\n",
            "Epoch 47/60\n",
            "781/781 [==============================] - 217s 277ms/step - loss: 0.2242 - acc: 0.9255 - val_loss: 2.1708 - val_acc: 0.6054\n",
            "Epoch 48/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.2250 - acc: 0.9253 - val_loss: 2.4106 - val_acc: 0.5734\n",
            "Epoch 49/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.2090 - acc: 0.9314 - val_loss: 2.7987 - val_acc: 0.5491\n",
            "Epoch 50/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.1996 - acc: 0.9335 - val_loss: 2.7447 - val_acc: 0.5625\n",
            "Epoch 51/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.1968 - acc: 0.9349 - val_loss: 2.9915 - val_acc: 0.5596\n",
            "Epoch 52/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.1924 - acc: 0.9360 - val_loss: 2.5778 - val_acc: 0.5915\n",
            "Epoch 53/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.1949 - acc: 0.9358 - val_loss: 2.7309 - val_acc: 0.5611\n",
            "Epoch 54/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.1807 - acc: 0.9406 - val_loss: 2.6406 - val_acc: 0.5779\n",
            "Epoch 55/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.1829 - acc: 0.9393 - val_loss: 2.5926 - val_acc: 0.5808\n",
            "Epoch 56/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.1760 - acc: 0.9413 - val_loss: 3.0533 - val_acc: 0.5550\n",
            "Epoch 57/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.1743 - acc: 0.9428 - val_loss: 2.6155 - val_acc: 0.5842\n",
            "Epoch 58/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.1747 - acc: 0.9424 - val_loss: 2.5488 - val_acc: 0.5895\n",
            "Epoch 59/60\n",
            "781/781 [==============================] - 217s 277ms/step - loss: 0.1689 - acc: 0.9449 - val_loss: 2.5576 - val_acc: 0.5999\n",
            "Epoch 60/60\n",
            "781/781 [==============================] - 217s 278ms/step - loss: 0.1671 - acc: 0.9445 - val_loss: 2.5315 - val_acc: 0.5927\n",
            "10000/10000 [==============================] - 15s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.5315316129684446, 0.5927]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "LiuaRRfiXZK6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}